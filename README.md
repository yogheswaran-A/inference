# inference

Qunatization visual guide https://www.maartengrootendorst.com/blog/quantization/   
Quantization, pruning, etc: https://intellabs.github.io/distiller/algo_quantization.html    
Fine-tuning LLMs to 1.58bit: extreme quantization made easy: https://huggingface.co/blog/1_58_llm_extreme_quantization   

