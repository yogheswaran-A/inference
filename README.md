# inference

Qunatization visual guide: https://www.maartengrootendorst.com/blog/quantization/   
Quantization, pruning, etc: https://intellabs.github.io/distiller/algo_quantization.html    
Fine-tuning LLMs to 1.58bit: extreme quantization made easy: https://huggingface.co/blog/1_58_llm_extreme_quantization   
Achieving FP32 Accuracy for INT8 Inference Using Quantization Aware Training with NVIDIA TensorRT: https://developer.nvidia.com/blog/achieving-fp32-accuracy-for-int8-inference-using-quantization-aware-training-with-tensorrt/   
Quantization in practice: https://pytorch.org/blog/quantization-in-practice/   
Quantization blog with codes: https://leimao.github.io/article/Neural-Networks-Quantization/#Introduction
